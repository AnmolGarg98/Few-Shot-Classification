{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nos.chdir(\"/kaggle/input/omniglot/\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-27T18:41:43.479809Z","iopub.execute_input":"2022-04-27T18:41:43.480111Z","iopub.status.idle":"2022-04-27T18:41:43.486201Z","shell.execute_reply.started":"2022-04-27T18:41:43.480083Z","shell.execute_reply":"2022-04-27T18:41:43.485521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport tqdm\nimport multiprocessing as mp\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\nimport torchvision","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2022-04-27T18:41:55.684444Z","iopub.execute_input":"2022-04-27T18:41:55.684783Z","iopub.status.idle":"2022-04-27T18:41:57.345185Z","shell.execute_reply.started":"2022-04-27T18:41:55.684751Z","shell.execute_reply":"2022-04-27T18:41:57.344308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataLoader():\n    def read_characters(self, dataset_directory, script_directory):\n        image_data = []\n        image_tag = []\n        characters = os.listdir(os.path.join(dataset_directory, script_directory))\n        \n        for char in characters:\n            images = os.listdir(os.path.join(dataset_directory,script_directory,char))\n\n            for img in images:\n                try:\n                    img_path = os.path.join(dataset_directory,script_directory,char,img)\n                    img_array = cv2.resize(cv2.imread(img_path),(28,28))\n                    \n                    img_rotated_90 = cv2.rotate(img_array, cv2.ROTATE_90_CLOCKWISE)\n                    img_rotated_180 = cv2.rotate(img_array, cv2.ROTATE_180)\n                    img_rotated_270 = cv2.rotate(img_array, cv2.ROTATE_90_COUNTERCLOCKWISE)\n                    # print(img_path)\n                    \n                    image_data.extend((img_array, img_rotated_90, img_rotated_180, img_rotated_270))\n                    image_tag.extend((\n                        script_directory+\"_\"+char+\"_\"+\"0\",\n                        script_directory+\"_\"+char+\"_\"+\"90\",\n                        script_directory+\"_\"+char+\"_\"+\"180\",\n                        script_directory+\"_\"+char+\"_\"+\"270\"\n                    ))\n                except AssertionError as error:\n                    print(error)\n        return np.array(image_data), np.array(image_tag)\n\n    def read_images(self, dataset_directory):\n        pool = mp.Pool(mp.cpu_count())\n        scripts_list = os.listdir(dataset_directory)\n        \n        results = [pool.apply(self.read_characters, args=(dataset_directory, scripts)) for scripts in scripts_list]\n        pool.close()\n\n        img_array = None\n        img_tag = None\n\n        for result in results:\n            if img_array is None:\n                img_array = result[0]\n                img_tag = result[1]\n            else:\n                img_array = np.vstack([img_array, result[0]])\n                img_tag = np.concatenate([img_tag, result[1]])\n        return img_array, img_tag\n\n    def extract_sample(self, n_way, n_shot, n_query, img_array, img_tag):\n        sample = []\n        K = np.random.choice(np.unique(img_tag), n_way, replace=False)\n        \n        for cls in K:\n            img_cls = img_array[img_tag == cls] # Choosing img with particular class\n            perm = np.random.permutation(img_cls) # Permuting them\n            sample_cls = perm[:(n_shot+n_query)] # Picking Support and Query images\n            sample.append(sample_cls)\n        \n        sample = np.array(sample)\n        sample = torch.from_numpy(sample).float()\n        sample = sample.permute(0,1,4,2,3) # reordering the images\n        return({\n            'images': sample,\n            'n_way': n_way,\n            'n_shot': n_shot,\n            'n_query': n_query\n            })","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:42:00.038405Z","iopub.execute_input":"2022-04-27T18:42:00.03872Z","iopub.status.idle":"2022-04-27T18:42:00.060868Z","shell.execute_reply.started":"2022-04-27T18:42:00.03869Z","shell.execute_reply":"2022-04-27T18:42:00.060121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self):\n        super(Encoder,self).__init__()\n        self.encoder()\n\n    def conv_block(self, in_channels, out_channels):\n        return nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(),\n            nn.MaxPool2d(2)\n        )\n\n    def encoder(self):\n        self.encode = nn.Sequential(\n            self.conv_block(3,64),\n            #self.conv_block(64,64),\n            self.conv_block(64,64),\n            self.conv_block(64,64),\n            nn.Flatten()\n        )\n\n    def forward(self, x):\n        return self.encode(x)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:42:04.444878Z","iopub.execute_input":"2022-04-27T18:42:04.445235Z","iopub.status.idle":"2022-04-27T18:42:04.453285Z","shell.execute_reply.started":"2022-04-27T18:42:04.445193Z","shell.execute_reply":"2022-04-27T18:42:04.452287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Protonet(nn.Module):\n    def __init__(self, Encoder):\n        super(Protonet, self).__init__()\n        self.Encoder = Encoder.cuda()\n\n    def Euclidean_Distance(self, x, y):\n        # x is a 2d matrix of each support units embedding-> (n_way*n_shot)x(d)\n        # y is a 2d matrix of each centroic -> (n_way)*(d)\n        # To Return: Euclidean distance of each point to centroid\n        # i.e. (n_way*n_shot)*(n_way)\n        \n        n = x.size(0) # number of training images\n        m = y.size(0) # number of classes\n        d = x.size(1) # size of embedding\n\n        x = x.unsqueeze(1).expand(n, m, d)\n        y = y.unsqueeze(0).expand(n, m, d)\n\n        return torch.pow(x - y, 2).sum(2)\n\n    def forward_loss(self, episode):\n        images = episode['images'].cuda()\n        n_way = episode['n_way']\n        n_shot = episode['n_shot']\n        n_query = episode['n_query']\n\n        img_support = images[:, :n_shot]\n        img_query = images[:, n_shot:]\n\n        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n        target_inds = Variable(target_inds, requires_grad=False)\n        target_inds = target_inds.cuda()\n\n        # encode images of the support and the query set\n        x = torch.cat([img_support.contiguous().view(n_way * n_shot, *img_support.size()[2:]),\n                       img_query.contiguous().view(n_way * n_query, *img_query.size()[2:])], 0)\n    \n        z = self.Encoder.forward(x)\n        z_dim = z.size(-1) # usually 64\n        z_proto = z[:n_way*n_shot].view(n_way, n_shot, z_dim).mean(1) # centroid\n        z_query = z[n_way*n_support:]\n\n        #compute distances\n        dists = self.Euclidean_Distance(z_query, z_proto)\n        \n        #compute probabilities\n        log_p_y = F.log_softmax(-dists, dim=1).view(n_way, n_query, -1)\n    \n        loss_val = -log_p_y.gather(2, target_inds).squeeze().view(-1).mean()\n        _, y_predicted = log_p_y.max(2)\n        acc_val = torch.eq(y_predicted, target_inds.squeeze()).float().mean()\n    \n        return loss_val, {\n            'loss': loss_val.item(),\n            'acc': acc_val.item(),\n            'y_predicted': y_predicted\n            }","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:42:08.589561Z","iopub.execute_input":"2022-04-27T18:42:08.589877Z","iopub.status.idle":"2022-04-27T18:42:08.608136Z","shell.execute_reply.started":"2022-04-27T18:42:08.589849Z","shell.execute_reply":"2022-04-27T18:42:08.607025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Train(nn.Module):\n    def __init__():\n        super(Train,self).__init__()\n\n    def train(model, optimizer, train_x, train_y, n_way, n_shot, n_query, max_epoch, epoch_size, dataloader):\n        scheduler = optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.5, last_epoch=-1)\n        epoch = 0\n        stop = False\n\n        while(epoch < max_epoch and stop==False):\n            running_loss = 0.0\n            running_acc = 0.0\n\n            for episode in tqdm.notebook.tnrange(epoch_size, desc=\"Epoch {:d} train\".format(epoch+1)):\n                sample = dataloader.extract_sample(n_way, n_support, n_query, train_x, train_y) # Extract episode data\n                \n                optimizer.zero_grad()\n                loss, output = model.forward_loss(sample)\n                \n                running_loss += output['loss']\n                running_acc += output['acc']\n                \n                loss.backward()\n                optimizer.step()\n\n            epoch_loss = running_loss / epoch_size\n            epoch_acc = running_acc / epoch_size\n            print('Epoch {:d} -- Loss: {:.4f} Acc: {:.4f}'.format(epoch+1,epoch_loss, epoch_acc))\n            epoch += 1\n            scheduler.step()\n\n    def test(model, test_x, test_y, n_way, n_shot, n_query, test_episode, dataloader):\n        running_loss = 0.0\n        running_acc = 0.0\n        for episode in tqdm.notebook.tnrange(test_episode):\n            sample = dataloader.extract_sample(n_way, n_shot, n_query, test_x, test_y)\n            loss, output = model.forward_loss(sample)\n            running_loss += output['loss']\n            running_acc += output['acc']\n        avg_loss = running_loss / test_episode\n        avg_acc = running_acc / test_episode\n        print('Test results -- Loss: {:.4f} Acc: {:.4f}'.format(avg_loss, avg_acc))\n        \n    def encode(episode, model):\n        images = episode['images'].cuda()\n        n_way = episode['n_way']\n        n_shot = episode['n_shot']\n        n_query = episode['n_query']\n\n        img_support = images[:, :n_shot]\n        img_query = images[:, n_shot:]\n\n        target_inds = torch.arange(0, n_way).view(n_way, 1, 1).expand(n_way, n_query, 1).long()\n        target_inds = Variable(target_inds, requires_grad=False)\n        target_inds = target_inds.cuda()\n\n        # encode images of the support and the query set\n        x = torch.cat([img_support.contiguous().view(n_way * n_shot, *img_support.size()[2:]),\n                       img_query.contiguous().view(n_way * n_query, *img_query.size()[2:])], 0)\n    \n        z = model.Encoder.forward(x)\n        z_dim = z.size(-1) # usually 64\n        z_proto = z[:n_way*n_shot].view(n_way, n_shot, z_dim).mean(1) # centroid\n        z_query = z[n_way*n_support:]\n        \n        return z, target_inds","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:42:13.783327Z","iopub.execute_input":"2022-04-27T18:42:13.783661Z","iopub.status.idle":"2022-04-27T18:42:13.804879Z","shell.execute_reply.started":"2022-04-27T18:42:13.78363Z","shell.execute_reply":"2022-04-27T18:42:13.803978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataloader = DataLoader()\ntrain_x, train_y = dataloader.read_images('images_background')\ntest_x, test_y = dataloader.read_images('images_evaluation')","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:42:20.659095Z","iopub.execute_input":"2022-04-27T18:42:20.659523Z","iopub.status.idle":"2022-04-27T18:44:55.670105Z","shell.execute_reply.started":"2022-04-27T18:42:20.659484Z","shell.execute_reply":"2022-04-27T18:44:55.66911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot as plt\n\ndef display_sample(sample):\n    \"\"\"\n    Displays sample in a grid\n    Args:\n        sample (torch.Tensor): sample of images to display\n    \"\"\"\n    # need 4D tensor to create grid, currently 5D\n    sample_4D = sample.view(sample.shape[0]*sample.shape[1],*sample.shape[2:])\n    # make a grid\n    out = torchvision.utils.make_grid(sample_4D, nrow=sample.shape[1])\n    plt.figure(figsize = (16,7))\n    plt.imshow(out.permute(1, 2, 0))\n\nsample_example = dataloader.extract_sample(8, 5, 5, train_x, train_y)\ndisplay_sample(sample_example['images'])","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:53:15.128367Z","iopub.execute_input":"2022-04-27T18:53:15.128739Z","iopub.status.idle":"2022-04-27T18:53:15.409053Z","shell.execute_reply.started":"2022-04-27T18:53:15.128705Z","shell.execute_reply":"2022-04-27T18:53:15.408123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = Encoder()\nmodel = Protonet(encoder)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T18:53:18.691244Z","iopub.execute_input":"2022-04-27T18:53:18.691569Z","iopub.status.idle":"2022-04-27T18:53:22.043185Z","shell.execute_reply.started":"2022-04-27T18:53:18.691539Z","shell.execute_reply":"2022-04-27T18:53:22.042142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr = 1e-3)\n\nn_way = 10\nn_support = 1\nn_query = 10\n\nmax_epoch = 5\nepoch_size = 1000\n\nTrain.train(model, optimizer, train_x, train_y, n_way, n_support, n_query, max_epoch, epoch_size, dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:29:58.209302Z","iopub.execute_input":"2022-04-27T19:29:58.209852Z","iopub.status.idle":"2022-04-27T19:34:24.224122Z","shell.execute_reply.started":"2022-04-27T19:29:58.209815Z","shell.execute_reply":"2022-04-27T19:34:24.223213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), \"/kaggle/working/prototype_model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:36:08.18649Z","iopub.execute_input":"2022-04-27T19:36:08.186843Z","iopub.status.idle":"2022-04-27T19:36:08.199251Z","shell.execute_reply.started":"2022-04-27T19:36:08.186806Z","shell.execute_reply":"2022-04-27T19:36:08.198132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"saved_model = Protonet(encoder)\nmodel.load_state_dict(torch.load(\"/kaggle/working/prototype_model.h5\"))\nmodel.eval()","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:36:10.730755Z","iopub.execute_input":"2022-04-27T19:36:10.731091Z","iopub.status.idle":"2022-04-27T19:36:10.746481Z","shell.execute_reply.started":"2022-04-27T19:36:10.73106Z","shell.execute_reply":"2022-04-27T19:36:10.745506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_way = 5\nn_support = 1\nn_query = 10\n\ntest_episode = 1000\n\nTrain.test(model, test_x, test_y, n_way, n_support, n_query, test_episode, dataloader)","metadata":{"execution":{"iopub.status.busy":"2022-04-27T19:36:29.622702Z","iopub.execute_input":"2022-04-27T19:36:29.623109Z","iopub.status.idle":"2022-04-27T19:36:54.212168Z","shell.execute_reply.started":"2022-04-27T19:36:29.623067Z","shell.execute_reply":"2022-04-27T19:36:54.211238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_sample = dataloader.extract_sample(n_way, n_support, n_query, test_x, test_y)\ndisplay_sample(my_sample['images'])","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:51:44.843158Z","iopub.execute_input":"2022-04-18T17:51:44.843506Z","iopub.status.idle":"2022-04-18T17:51:45.044764Z","shell.execute_reply.started":"2022-04-18T17:51:44.84347Z","shell.execute_reply":"2022-04-18T17:51:45.043686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_loss, my_output = model.forward_loss(my_sample)\nmy_output","metadata":{"execution":{"iopub.status.busy":"2022-04-18T17:52:06.789036Z","iopub.execute_input":"2022-04-18T17:52:06.789382Z","iopub.status.idle":"2022-04-18T17:52:06.801402Z","shell.execute_reply.started":"2022-04-18T17:52:06.789349Z","shell.execute_reply":"2022-04-18T17:52:06.800348Z"},"trusted":true},"execution_count":null,"outputs":[]}]}